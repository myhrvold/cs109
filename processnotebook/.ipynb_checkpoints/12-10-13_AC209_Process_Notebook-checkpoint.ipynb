{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scripting Hollywood Success: What Data Science Can Tell Us About Feature Film Scripts"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b> AC209 Data Science Final Project Process Notebook, Fall 2013 </b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<i>Daniel Newman, J. Benjamin Cook, Ryan Lee, and Conor L. Myhrvold<i/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"http://upload.wikimedia.org/wikipedia/commons/5/5c/Screenwriting-pro-interface-default.jpg\" width=\"600\" height=\"450\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<i><font size=1> Source: Wikimedia Commons</font> </i>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b><p><i><font size=3>In the dizzying world of moviemaking, we must not be distracted from one fundamental concept: the idea is king. Stars, directors, writers, hardware, special effects, new sound systems\u2026 all of these can have a role to play in the success of a film, but they must all serve as humble subjects to the supremacy of the idea. If a movie begins with a great, original idea, chances are good it will be successful, even if it is executed only marginally well. However, if a film begins with a flawed idea, it will most certainly fail, even if it is made with \u201cA\u201d talent and marketed to the hilt.</font></i></p></b>\n",
      "\n",
      "<p><font size=3> - Jeffrey Katzenberg, </font><a href=\"http://www.lettersofnote.com/2011/11/some-thoughts-on-our-business.html\" target=\"_blank\">\"Some Thoughts On Our Business<a/><font size =3> ,Disney Internal Memo, Jan 11, 1991 </font> <p/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "##\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "##\n",
      "import urllib\n",
      "import urllib2 \n",
      "from bs4 import BeautifulSoup\n",
      "import html2text\n",
      "import json\n",
      "import ast\n",
      "import requests\n",
      "import os\n",
      "##\n",
      "import string\n",
      "import re\n",
      "import operator\n",
      "from operator import itemgetter\n",
      "##\n",
      "import gensim\n",
      "import vocabulary\n",
      "##\n",
      "from sklearn import linear_model\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import mean_squared_error\n",
      "##\n",
      "from IPython.display import Image\n",
      "##\n",
      "import matplotlib.pyplot as plt\n",
      "import brewer2mpl\n",
      "from matplotlib import rcParams\n",
      "dark2_colors = brewer2mpl.get_map('Dark2', 'Qualitative', 7).mpl_colors\n",
      "##\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'white'\n",
      "rcParams['patch.facecolor'] = dark2_colors[0]\n",
      "rcParams['font.family'] = 'StixGeneral'\n",
      "##\n",
      "import glob\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_border(axes=None, top=False, right=False, left=True, bottom=True):\n",
      "    \"\"\"\n",
      "    Minimize chartjunk by stripping out \n",
      "    unnecesasry plot borders and axis ticks\n",
      "    \n",
      "    The top/right/left/bottom keywords toggle \n",
      "    whether the corresponding plot border is drawn\n",
      "    \"\"\"\n",
      "    ax = axes or plt.gca()\n",
      "    ax.spines['top'].set_visible(top)\n",
      "    ax.spines['right'].set_visible(right)\n",
      "    ax.spines['left'].set_visible(left)\n",
      "    ax.spines['bottom'].set_visible(bottom)\n",
      "    \n",
      "    #turn off all ticks\n",
      "    ax.yaxis.set_ticks_position('none')\n",
      "    ax.xaxis.set_ticks_position('none')\n",
      "    \n",
      "    #now re-enable visibles\n",
      "    if top:\n",
      "        ax.xaxis.tick_top()\n",
      "    if bottom:\n",
      "        ax.xaxis.tick_bottom()\n",
      "    if left:\n",
      "        ax.yaxis.tick_left()\n",
      "    if right:\n",
      "        ax.yaxis.tick_right()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Overview and Motivation </font> </b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"https://dl.dropboxusercontent.com/u/14868427/hitchcock.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are interested in what makes good writing for an unusual medium: the Hollywood Blockbuster. Exactly what makes a great script is <a href=\"http://www.theguardian.com/books/2013/mar/15/john-yorke-best-screenwriting\" target=\"_blank\">out for debate</a>. However, predicting the success of a movie before it has been filmed -- while it is still in script stages -- is unequivocally considered to be an important problem because the difference between a hit and a flop is hundreds of millions of dollars per movie. \n",
      "\n",
      "A movie script is equivalent to the business plan for an early stage startup, before it has raised lots of money. Like a successful startup, there are many factors that determine box office success and critical acclaim apart from its initial blueprint, but it is likely that one of those factors is the quality of the script as that is the original basis upon which the movie is built.\n",
      "\n",
      "Scripts are highly formatted and stylized, which makes them ripe for the sort of analysis we want to undertake. Each TV studio has its own script formatting process, and film scripts -- which we examine for this project -- have an easy-to-read structure. Screenwriting software such as FinalDraft exists to automatically adhere to a particular style, like academic citation styles. \n",
      "\n",
      "Scripts are perhaps the most expensive writing on a per word basis. Top scripts regularly sell for the low seven figures, <a href=\"http://gointothestory.blcklst.com/2012/07/the-definitive-list-of-spec-script-sales-1991-2012-every-link.html\" target=\"_blank\"> with most in the six figure range <a/>. Freelance writers revising a script are paid on the order of $10,000+/week during revisions that can last up to several years as the movie is being developed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<u><font size=3> Script Analysis </font></u>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a dearth of analysis about movie scripts. This is in part because of their ephemeral nature. The final product of the movie is the film itself rather that the writing. Unlike a lot of professional writing, most scripts are written \u201con spec\u201d. They are completed with little input from potential studios which will purchase them. In magazine, book, and software writing, a contract is generally in place as the writing product is being created. For more background, see: <a href=\"http://gointothestory.blcklst.com/2013/06/the-business-of-screenwriting-everything-you-wanted-to-know-about-specs-part-19.html\" target=\"_blank\">The Business of Screenwriting: Everything You Wanted to Know About Specs</a> . Similarly, unlike most other writing products, the script is often not even close to the final writing product that\u2019s evaluated. Once purchased, scripts undergo several intensive rewrites before a \u201cshooting script\u201d is developed, which serves as the final version as filming is taken place. During filming there are still ad-libbed lines, and iterative improvements depending on how the actual filming schedule is progressing and how good the scenes are, that have been finished.\n",
      "\n",
      "Despite these drawbacks, the overwhelming financial incentive to use scripts as a movie prediction mechanism -- before all of the money has bene spent making the movie -- has attracted several high profile attempts to use script features from scripts of previously successful or unsuccessful movies to anticipate what a movie should have in it to make money.\n",
      "\n",
      "Malcolm Gladwell's 2006 profile in <i>The New Yorker</i> <a href=\"http://www.newyorker.com/archive/2006/10/16/061016fa_fact6?currentPage=all\" target=\"_blank\">The Formula: What if you built a machine to predict hit movies?<a/>, as well a 2013 <i> New York Times Magazine </i> feature story <a href=\"http://www.nytimes.com/2013/05/06/business/media/solving-equation-of-a-hit-film-script-with-data.html?pagewanted=all\" target=\"_blank\"> Solving Equation of a Hit Film Script, With Data<a/> show an increasing interest in script analytics. (With <a href=\"http://blog.blcklst.com/category/vinny-bruzzese/\" target=\"_blank\">criticism<a/> from the screenwriting community. See <a href=\"http://livingromcom.typepad.com/my_weblog/2013/05/the-devil-we-know.htmlthis\" target=\"_blank\">further<a/> critiques <a href=\"http://www.huffingtonpost.com/seth-jaret/the-algorithm-of-hollywoo_b_3246877.html\" target=\"_blank\">as well<a/>.)\n",
      "\n",
      "So we decided to do some of our own, at a higher and broader level than the scene-by-scene analysis which would be outside the scope in this project, using tools and techniques learned through our <a href=\"http://www.cs109.org/\" target=\"_blank\">Data Science <a/> course.\n",
      "\n",
      "For this project, we characterized the properties of ~400 produced movie scripts through text analysis, and correlated those features to other movie features we obtained, such as the critical acclaim of the movie (as inferred from audience and critic scores from <a href=\"http://www.rottentomatoes.com/\" target=\"_blank\">Rotten Tomatoes<a/>), its estimated budget and domestic box office haul, Academy Award nominations, lead actors and actresses and other movie data that can be found on sites like <a href=\"http://www.imdb.com/\" target=\"_blank\">IMBD<a/>, in addition to other movie news and reports websites.\n",
      "\n",
      "On a simpler level, we also test whether some of the conventional wisdoms about produced scripts hold up under our dataset, as few Hollywood executive or screenwriting gurus have conducted any sort of quantitative analysis of the cumulative scripts they've read."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Related Work </font></b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Apart from the above, we're inspired by the eventual, and probably inevitable, transfer of our general techniques on the recent script rating exchange <a href=\"http://blcklst.com/\" target=\"_blank\">The Black List<a/>. The Black List is a means of evaluating scripts (which launched October 2012) via an accessible database patrolled by screenwriters who upload their completed scripts, and executives wishing to make purchases, and non-purchasing screenwriter professionals who rate the scripts for a fee which can help distinguish a script from the rest of the pack. It started out as a <a href=\"http://blcklst.com/lists/\" target=\"_blank\">manually curated list of the top spec scripts that weren't sold yet.</a>\n",
      "\n",
      "Since the Black List has <a href=\"http://nofilmschool.com/2012/11/black-list-paid-screenplay-service-data-first-month/\" target=\"_blank\">its own rating system and spec scrip database<a/> -- the first of its kind, and fast growing -- we could eventually use that rating as a predictor once we know the outcomes from their scripts; but a first step of figuring out unproduced scripts, is to see trends of the performance of produced scripts as well as their characteristics. And that is the scope of our project.\n",
      "\n",
      "We're also inspired by notion that great screen writing can now be recognized even if it's <a href=\"http://www.wired.com/underwire/2012/03/ff_reddit/all/1\" target=\"_blank\"> a small snippet<a/>, as was the case in a <a href=\"http://www.reddit.com/r/AskReddit/comments/k067x/could_i_destroy_the_entire_roman_empire_during/c2giwm4\" target=\"_blank\">recent Reddit post<a/> written in a screenplay style which, upon going viral, reached a movie executive who bought the rights to it. This fortuitous occurrence could be manufactured on a greater scale if computer programs analyzed text instead of crowd sourcing human evaluators.\n",
      "\n",
      "For box office prediction papers, see the References section at the end."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Initial Questions </font> </b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p> There are two principal questions we are attempting to address: </p>\n",
      "<p> <b>1)</b> To what extent can a movie script features predict box office success or critical reviews of the final film? </p>\n",
      "<p> <b>2)</b> What other script features could give us insights about the movie making process counter \"conventional\" Hollywood wisdom? </p>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b> Question: How long is the average screenplay really? Are there genre differences? </b>\n",
      "\n",
      "<u>Source 1: </u><i>\"The average feature screenplay, traditionally, is between 95 and 125 pages long. In Hollywood these days scripts generally don't run longer than 114 pages. Comedy scripts are typically shorter, dramas longer. There are, naturally, variations. You could be writing an action-packed film where your description takes only 10 seconds to read, but will take 45 seconds of film time.\"</i> - <a href=\"http://www.screenwriting.info/03.php\" target=\"_blank\"> screenwriting.info </a>\n",
      "\n",
      "<u>Source 2: </u><i>\"In a script, there are approximately 125 words of dialogue per minute. This estimate is based upon recent American films. The words of dialogue per minute might range from 50 to 200 within a script. Of course, it is possible to have no dialogue, making time estimates more difficult.\"</i> - <a href=\"http://www.tameri.com/format/wordcounts.html\" target=\"_blank\"> tameri.com </a>\n",
      "\n",
      "<u>Source 3:</u> <i> \"Size matters... at least length. Another favorite Hollywood argument (without argument, there would be no Hollywood) is about script length. The common rule that many spit out is: \"One page of film script equals one minute of screen time.\" This means that, since the average film is 2 hours long (or 120 minutes for the mathematically challenged), a script should be 120 pages... regardless of reality, Hollywood expects film scripts to be about 120 pages. 115 is okay. 125 is okay, too. 90 is not good and neither is 140.\" </i> \n",
      "- <a href=\"http://www.scriptwritingsecrets.com/Size_Matters.htm\" target=\"_blank\"> scriptwritingsecrets.com </a>\n",
      "\n",
      "<u>Source 4: </u><i> \"In general, script lengths have become shorter through the years. In the old days it was standard to see script in the 120-135 page length. Some of the 1980\u2032s action scripts are in the 156 page range. But with A.D.D. and short attention spans of the average reader in Hollywood, the current average script length is at 107 pages...It\u2019s generally accepted that 1 page of screenplay = one minute of screentime. That is if you use 12 point Courier and have the correct left and right margins and the correct header and footer spacing...Genre expectations for page count:</i>\n",
      "<i>Drama \u2013 118, Thriller- 115, RomCom \u2013 110, Comedy \u2013 107, Action \u2013 105, Horror \u2013 95</i>\n",
      "<i>The page counts are not absolute, and nothings carved in stone. All rules have exceptions. Nonetheless, if you deliver a script in the 105-110 range you\u2019ll be fine.\"</i>\n",
      "- <a href=\"http://www.humanities360.com/index.php/determining-the-ideal-length-for-a-screenplay-2-68331/\" target=\"_blank\"> humanities360.com </a>\n",
      "\n",
      "<i>========================================================================================================================</i>\n",
      "\n",
      "\n",
      "Computing average script length by genre, we found the following:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "                    Genre |    Avg. Length |   Avg. Runtime\n",
      "---------------------------------------------------------------\n",
      "       Action & Adventure |    3405.7 words|   115.6 minutes\n",
      "                Animation |    2872.1 words|    77.0 minutes\n",
      "Art House & International |    2860.5 words|   108.2 minutes\n",
      "                 Classics |    3214.3 words|   114.8 minutes\n",
      "                   Comedy |    2685.0 words|   106.0 minutes\n",
      "              Cult Movies |    2681.0 words|   114.8 minutes\n",
      "              Documentary |    4182.0 words|    76.8 minutes\n",
      "                    Drama |    3108.2 words|   120.6 minutes\n",
      "                   Horror |    2771.3 words|   101.5 minutes\n",
      "            Kids & Family |    2697.0 words|    97.2 minutes\n",
      "Musical & Performing Arts |    2861.3 words|   108.6 minutes\n",
      "       Mystery & Suspense |    3183.9 words|   115.9 minutes\n",
      "                  Romance |    2880.7 words|   115.8 minutes\n",
      "Science Fiction & Fantasy |    3293.7 words|   109.3 minutes\n",
      "         Special Interest |    2911.5 words|   120.5 minutes\n",
      "               Television |    2596.6 words|   109.8 minutes\n",
      "                  Western |    3697.0 words|   128.2 minutes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Hollywood conventional wisdom says that Horror, Comedy and Family-oriented movies are the shortest and that Television movies are shorter than most other movies. We find this in our results. The fact that Animation movies and Documentaries are on the short end is not surprising. We do find that Actiona & Adventure is longer than what conventional wisdom says, but this may be partly due to the fact that each movie is tagged with multiple genres in the Rotten Tomatoes database. This analysis could be further extended by estimating how much dialogue there is in a script and by seeing how many pages we would estimate versus what actually happened. We know this because we are able to take diaglogue from an IMDB movie and return it using some of our functions below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"https://dl.dropboxusercontent.com/u/14868427/script_length_distro.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Data </font></b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "From where and how are you collecting your data?\n",
      "\n",
      "We will use a combination of web scraping, APIs and manual data collection in order to get our data.  So far, we have obtained over 300 scripts from \u201chttp://www.dailyscript.com/\u201d. We believe that this will be a sufficient data set to start with. We also have IMDB numbers for all of these movies, which will allow us to link up the scripts with information from IMDB, Rotten Tomatoes and other sources.\n",
      "\n",
      "Our data will be collected from two primary sources: an online scripts database (of which there are many -- right now we have used Daily Script), and a movie box office database (of which Rotten Tomatoes is among the ones which have some of this information.) Fortuitously, most online scripts are readily accessible and stored in text format because scripts are freely shared; after a movie\u2019s release, the script is considered something of a fan extra that can help continue to drive interest in the movie, akin the lyrics of a song.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LIST_OF_GENRES = [\"Action & Adventure\",\"Animation\",\n",
      "\"Art House & International\",\"Classics\",\"Comedy\",\"Cult Movies\",\n",
      "\"Documentary\",\"Drama\",\"Horror\",\"Kids & Family\",\n",
      "\"Musical & Performing Arts\",\"Mystery & Suspense\",\"Romance\",\n",
      "\"Science Fiction & Fantasy\",\"Special Interest\",\"Television\",\"Western\"]\n",
      "\n",
      "\n",
      "def scrape_daily_script(Request,urlopen,imdb_num_list):\n",
      "    listOfUrls = ['http://www.dailyscript.com/movie.html', 'http://www.dailyscript.com/movie_n-z.html']\n",
      "    homepage = \"http://www.dailyscript.com/\"\n",
      "\n",
      "    imdbNumDict = {}\n",
      "\n",
      "    for each_page in listOfUrls:\n",
      "        theurl = each_page\n",
      "        txdata = None                                                                           # if we were making a POST type request, we could encode a dictionary of values here - using urllib.urlencode\n",
      "        txheaders =  {'User-agent' : 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'}          # fake a user agent, some websites (like google) don't like automated exploration\n",
      "\n",
      "        try:\n",
      "            req = Request(theurl, txdata, txheaders)            # create a request object\n",
      "            handle = urlopen(req)                               # and open it to return a handle on the url\n",
      "        except IOError, e:\n",
      "            print 'We failed to open \"%s\".' % theurl\n",
      "            if hasattr(e, 'code'):\n",
      "                print 'We failed with error code - %s.' % e.code\n",
      "\n",
      "        sHTML = handle.read()\n",
      "        sHTML = sHTML.replace('ISO-8859-1', 'utf-8')\n",
      "        soup = BeautifulSoup(sHTML, \"html5lib\")\n",
      "        movieLinks = soup.find_all(\"p\")\n",
      "        for elem in movieLinks:\n",
      "            if \"scripts\" in str(elem):\n",
      "                links = elem.find_all(\"a\")\n",
      "                for link in links:\n",
      "                    if \"scripts\" in str(link):\n",
      "                        scriptlink =  homepage + link['href']\n",
      "                        title = link.get_text()\n",
      "                        title = title.replace(\"/\",\"-\")\n",
      "                    if \"imdb\" in str(link):\n",
      "                        imdb_link = link['href']\n",
      "                        #grab the imdb number from the link\n",
      "                        imdbNum = imdb_link[-imdb_link[::-1].find(\"?\"):]\n",
      "        \n",
      "                #doctype (e.g. pdf, html, txt) is gonna be grabbed as the \n",
      "                #letters after the LAST period in the link to the script\n",
      "                doctype = scriptlink[-scriptlink[::-1].find(\".\"):]\n",
      "                doctype = doctype.lower()\n",
      "\n",
      "                if doctype <> \"pdf\" and doctype <> \"doc\" and len(imdbNum) > 1:\n",
      "                    try:\n",
      "                        if imdbNum not in imdbNumDict.keys():\n",
      "                            imdbNumDict[imdbNum] = \"1\"\n",
      "                            req = Request(scriptlink, txdata, txheaders)\n",
      "                            handle = urlopen(req)\n",
      "                            sHTML_script = handle.read()\n",
      "                            if doctype == \"html\" or doctype == \"htm\":\n",
      "                                 sHTML_script = html2text.html2text(sHTML_script)\n",
      "                                 doctype = \"txt\"\n",
      "                            \n",
      "                            if len(sHTML_script) > 10000:\n",
      "                                if title.encode('ascii', 'replace') == title:\n",
      "                                    f = open(\"output_v3/\" + imdbNum + \".\" + doctype, 'w')\n",
      "                                    f.write(sHTML_script)\n",
      "                                    f.close()\n",
      "                                    imdb_num_list.append(imdbNum)\n",
      "                                    print imdbNum\n",
      "                    except:\n",
      "                        pass\n",
      "    return imdb_num_list\n",
      "\n",
      "\n",
      "def scrape_simply_scripts(Request,urlopen,imdb_num_list):\n",
      "    listOfUrls = ['http://www.simplyscripts.com/num.html', \n",
      "                  'http://www.simplyscripts.com/a.html',\n",
      "                  'http://www.simplyscripts.com/b.html',\n",
      "                  'http://www.simplyscripts.com/c.html',\n",
      "                  'http://www.simplyscripts.com/d.html',\n",
      "                  'http://www.simplyscripts.com/e.html',\n",
      "                  'http://www.simplyscripts.com/f.html',\n",
      "                  'http://www.simplyscripts.com/g.html',\n",
      "                  'http://www.simplyscripts.com/h.html',\n",
      "                  'http://www.simplyscripts.com/i.html',\n",
      "                  'http://www.simplyscripts.com/j.html',\n",
      "                  'http://www.simplyscripts.com/k.html',\n",
      "                  'http://www.simplyscripts.com/l.html',\n",
      "                  'http://www.simplyscripts.com/m.html',\n",
      "                  'http://www.simplyscripts.com/n.html',\n",
      "                  'http://www.simplyscripts.com/o.html',\n",
      "                  'http://www.simplyscripts.com/p.html',\n",
      "                  'http://www.simplyscripts.com/q.html',\n",
      "                  'http://www.simplyscripts.com/r.html',\n",
      "                  'http://www.simplyscripts.com/s.html',\n",
      "                  'http://www.simplyscripts.com/t.html',\n",
      "                  'http://www.simplyscripts.com/uvw.html',\n",
      "                  'http://www.simplyscripts.com/xyz.html']\n",
      "                  \n",
      "    imdbNumDict = {}\n",
      "\n",
      "    for each_page in listOfUrls:\n",
      "        print each_page\n",
      "        theurl = each_page\n",
      "        txdata = None                                                                           # if we were making a POST type request, we could encode a dictionary of values here - using urllib.urlencode\n",
      "        txheaders =  {'User-agent' : 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'}          # fake a user agent, some websites (like google) don't like automated exploration\n",
      "\n",
      "        try:\n",
      "            req = Request(theurl, txdata, txheaders)            # create a request object\n",
      "            handle = urlopen(req)                               # and open it to return a handle on the url\n",
      "        except IOError, e:\n",
      "            print 'We failed to open \"%s\".' % theurl\n",
      "            if hasattr(e, 'code'):\n",
      "                print 'We failed with error code - %s.' % e.code\n",
      "\n",
      "        sHTML = handle.read()\n",
      "        sHTML = sHTML.replace('ISO-8859-1', 'utf-8')\n",
      "        soup = BeautifulSoup(sHTML, \"html5lib\")\n",
      "        movieLinks = soup.find_all(\"tr\")\n",
      "        \n",
      "        for movie in movieLinks:\n",
      "            imdbNum = \"\"\n",
      "            if (\"imdb\" in str(movie) and \"dailyscript\" not in str(movie) \n",
      "                and (\"in html format\" in str(movie) or \"in text format\" \n",
      "                in str(movie))):\n",
      "                \n",
      "                links = movie.find_all(\"a\")\n",
      "                script_link = links[0]['href']\n",
      "                for link in links:\n",
      "                    if \"imdb\" in str(link):\n",
      "                        sLink = link['href']\n",
      "                        imdbNum = sLink[sLink.find(\"?\")+1:]\n",
      "                        \n",
      "                #~ #doctype (e.g. pdf, html, txt) is gonna be grabbed as the \n",
      "                #~ #letters after the LAST period in the link to the script\n",
      "                doctype = script_link[-script_link[::-1].find(\".\"):]\n",
      "                doctype = doctype.lower()\n",
      "    \n",
      "                if len(imdbNum) > 1 and imdbNum.isdigit(): #only grab scripts with valid IMDB numbers\n",
      "                    try:\n",
      "                        if imdbNum not in imdbNumDict.keys():\n",
      "                            imdbNumDict[imdbNum] = \"1\"\n",
      "                            req = Request(script_link, txdata, txheaders)\n",
      "                            handle = urlopen(req)\n",
      "                            sHTML_script = handle.read()\n",
      "                            if \"htm\" in doctype:\n",
      "                                 sHTML_script = html2text.html2text(sHTML_script)\n",
      "                                 doctype = \"txt\"\n",
      "                            if len(sHTML_script) > 10000:\n",
      "                                \n",
      "                                f = open(\"output_v3/\" + imdbNum + \".\" + doctype, 'w')\n",
      "                                f.write(sHTML_script)\n",
      "                                f.close()\n",
      "                                imdb_num_list.append(imdbNum)\n",
      "                                print imdbNum\n",
      "                    except:\n",
      "                        pass\n",
      "    return imdb_num_list\n",
      "    \n",
      "def grab_rotten_tomatoes_info(dataList, datafile,box_office_dict,academy_award_dict):\n",
      "    for elem in dataList:\n",
      "        api_key = '6mhbr2qxeswq3znchkshxtta'\n",
      "        imdb_id = elem  \n",
      "        url = \"http://api.rottentomatoes.com/api/public/v1.0/movie_alias.json?id=%s&type=imdb&apikey=%s\" % (imdb_id,  api_key)\n",
      "        data = requests.get(url).text\n",
      "        data = json.loads(data)  # load a json string into a collection of lists and dicts\n",
      "        if imdb_id <> \"0000000\" and os.path.getsize('output/'+str(imdb_id)+'.txt')>35000: #if script is less than 35kb, disregard it\n",
      "            try:\n",
      "                rt_id = json.dumps(data['id'])  \n",
      "                genres = json.dumps(data['genres']).replace(\"[\",\"\").replace(\"]\",\"\").replace(chr(34),\"\").split(\", \")\n",
      "                ratings = data['ratings']\n",
      "                ratingslist = []\n",
      "                critics_score = \"\"\n",
      "                critics_rating = \"\"\n",
      "                audience_rating = \"\"\n",
      "                audience_score = \"\"\n",
      "                if \"critics_score\" in ratings.keys():\n",
      "                    critics_score = str(ratings[\"critics_score\"])\n",
      "                if \"critics_rating\" in ratings.keys():\n",
      "                    critics_rating = str(ratings[\"critics_rating\"])\n",
      "                if \"audience_rating\" in ratings.keys():\n",
      "                    audience_rating = str(ratings[\"audience_rating\"])\n",
      "                if \"audience_score\" in ratings.keys():\n",
      "                    audience_score = str(ratings[\"audience_score\"])\n",
      "                MPAA_Rating = json.dumps(data['mpaa_rating'])\n",
      "                runtime = json.dumps(data['runtime']) \n",
      "                year = json.dumps(data['year']) \n",
      "                title = json.dumps(data['title'])\n",
      "                characters = data['abridged_cast']\n",
      "                datafile.write(imdb_id +  chr(9))\n",
      "                datafile.write(rt_id  + chr(9))\n",
      "                datafile.write(title + chr(9))\n",
      "                for elem in LIST_OF_GENRES:\n",
      "                    if elem in genres:\n",
      "                        datafile.write(\"1\" + chr(9))\n",
      "                    else:\n",
      "                        datafile.write(\"0\" + chr(9))\n",
      "                datafile.write(critics_score + chr(9))\n",
      "                datafile.write(audience_score + chr(9))\n",
      "                datafile.write(audience_rating + chr(9))\n",
      "                datafile.write(critics_rating + chr(9))\n",
      "                datafile.write(str(runtime) + chr(9))\n",
      "                datafile.write(str(year) + chr(9))\n",
      "                datafile.write(MPAA_Rating + chr(9))\n",
      "                for i in range(5):\n",
      "                    if i+1 > len(characters):\n",
      "                        datafile.write(\"\" + chr(9) + \"\" + chr(9))\n",
      "                    else:\n",
      "                        if \"name\" in characters[i].keys():\n",
      "                            datafile.write(characters[i][\"name\"] + chr(9))\n",
      "                        else:\n",
      "                            datafile.write(\"\" + chr(9))\n",
      "                        if \"characters\" in characters[i].keys():\n",
      "                            datafile.write(characters[i][\"characters\"][0] + chr(9))\n",
      "                        else:\n",
      "                            datafile.write(\"\" + chr(9))\n",
      "                if imdb_id in box_office_dict.keys():\n",
      "                    datafile.write(box_office_dict[imdb_id][0] + chr(9))\n",
      "                    datafile.write(box_office_dict[imdb_id][1] + chr(9))\n",
      "                else:\n",
      "                    datafile.write(\"\" + chr(9))\n",
      "                    datafile.write(\"\" + chr(9))\n",
      "                if imdb_id in academy_award_dict.keys():\n",
      "                    datafile.write(academy_award_dict[imdb_id][0] + chr(9))\n",
      "                    datafile.write(academy_award_dict[imdb_id][1] + chr(9))\n",
      "                else:\n",
      "                    datafile.write(\"\" + chr(9))\n",
      "                    datafile.write(\"\" + chr(9))\n",
      "                datafile.write(\"\\n\")\n",
      "            except:\n",
      "                pass    \n",
      "\n",
      "#import box office info and put into dictionary\n",
      "box_office_info = np.genfromtxt(\"boxoffice.csv\", delimiter='\\t', dtype=str,skip_header=1)\n",
      "box_office_dict = {}\n",
      "for elem in box_office_info:\n",
      "    box_office_dict[elem[0]] = [elem[1],elem[2]]\n",
      "\n",
      "#import academy award info and put into dictionary\n",
      "academy_award_info = np.genfromtxt(\"OscarInfo.csv\", delimiter='\\t', dtype=str,skip_header=1)\n",
      "academy_award_dict = {}\n",
      "for elem in academy_award_info:\n",
      "    academy_award_dict[elem[0]] = [elem[1],elem[2]]\n",
      "\n",
      "\n",
      "imdb_num_list = []\n",
      "datafile = open('MasterList_v3.tsv','w')\n",
      "datafile.write(\"IMDB ID\" + chr(9) + \"Rotten Tomatoes ID\" + chr(9) + \n",
      "                \"Title\" + chr(9))\n",
      "for elem in LIST_OF_GENRES:\n",
      "    datafile.write(elem + chr(9))\n",
      "    \n",
      "datafile.write(\"Critics Score\" + chr(9) + \"Audience Score\" + chr(9) + \n",
      "    \"Audience Rating\" + chr(9) + \"Critics Rating\" + chr(9) + \"runtime\" + \n",
      "    chr(9) + \"year\" + chr(9) + \"mpaa_rating\" + chr(9)+ \"actor1\" + chr(9)\n",
      "    + \"character1\" + chr(9) + \"actor2\" + chr(9) + \"character2\" + chr(9) \n",
      "    + \"actor3\" + chr(9) + \"character3\" + chr(9)\n",
      "    + \"actor4\" + chr(9) + \"character4\" + chr(9)\n",
      "    + \"actor5\" + chr(9) + \"character5\" + chr(9)\n",
      "    + \"Budget\" + chr(9) + \"Gross\" + chr(9) + \"Oscar Wins\" \n",
      "    + chr(9) + \"Oscar Nominations\" + \"\\n\")\n",
      "    \n",
      "urlopen = urllib2.urlopen\n",
      "Request = urllib2.Request\n",
      "imdb_num_list = scrape_daily_script(Request,urlopen,imdb_num_list)\n",
      "imdb_num_list = scrape_simply_scripts(Request,urlopen,imdb_num_list)\n",
      "\n",
      "imdb_num_list = list(set(imdb_num_list)) #remove any duplicates\n",
      "\n",
      "grab_rotten_tomatoes_info(imdb_num_list,datafile,box_office_dict, academy_award_dict)\n",
      "\n",
      "datafile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0147800\n",
        "0114746"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0146309"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0179626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0134273"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096754"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0078748"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0094631"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0090605"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0086879"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0244000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0163651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0082010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0254099"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0053604"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119822"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0112401"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118655"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0072684"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0103772"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096895"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0103776"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0115641"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0078841"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0095250"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0268995"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0187738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0221027"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0037549"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0163988"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0092699"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0103893"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0112641"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0209958"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0071315"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0124315"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0109445"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0112722"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0139134"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0104036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0069945"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0068451"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0077416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0072890"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0157503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0023969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0131369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0126886"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097289"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0082348"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097322"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116282"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083929"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0195714"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0309593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0065724"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0240507"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0240510"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0329101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0186151"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0211443"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083987"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0288477"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0162346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0071562"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0187078"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0099703"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119229"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0077651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0171363"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097493"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0095294"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093177"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0185371"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102070"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0036027"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119349"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116629"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097576"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0087469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0140352"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0099871"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0073195"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102138"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0067309"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119488"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0104691"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097737"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0264796"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0165854"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0185431"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0199725"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0066026"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0175880"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0091474"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0070379"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0209144"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0064665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0077928"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119675"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0100157"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120755"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093565"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0031679"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119280"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0166924"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0110632"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0195945"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0107688"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093629"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0171580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0190590"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0258000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0187393"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0213149"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0098084"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0107818"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0134847"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0091763"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0054215"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0272338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0239860"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0081398"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102753"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0089880"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0048545"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0199753"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120004"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120801"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0075148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0122690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0266915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0128445"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0111127"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0114369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0050976"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0073692"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0111161"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0081505"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0286106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0090021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0258153"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0167404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0162661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120834"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0307479"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120157"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0158983"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120184"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0145487"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0079945"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120686"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0186589"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0043014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0051036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0117802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0129387"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0025878"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0268695"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0054387"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0100791"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0092099"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0114709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0181865"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0092106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120399"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0217869"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0105695"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0084855"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0052357"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0281358"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0094291"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0094336"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0090329"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120902"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/num.html\n",
        "0103594"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0062622"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083511"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0134273"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/a.html\n",
        "0053619"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0086856"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0088683\n",
        "0078748"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0103644"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0090605"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0169547"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0112346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118617"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0075686"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0078788\n",
        "0106302"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0106303\n",
        "0120591"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0106308"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119822\n",
        "0132512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0052587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0145660"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/b.html\n",
        "0215545"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0115632\n",
        "0015648"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0077215"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118689"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118715"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096933"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0187738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118745"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0090756"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0106453\n",
        "0181984"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0166110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0061418"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0115736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0112573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0088846"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0112594"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0094812\n",
        "http://www.simplyscripts.com/c.html\n",
        "0162908"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0056923"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0021733"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0024969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0175526"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0163579"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0071315\n",
        "0033467"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0109445\n",
        "0061512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0115964"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0190332"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0109506"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0115986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0167099"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/d.html\n",
        "0088993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097165"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118956"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0033532"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097216\n",
        "0120655"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0057012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0087182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/e.html\n",
        "0080678"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0080684"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116225"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0067065\n",
        "0083907"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0092991"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/f.html"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0060397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0104257"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119116"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097366"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0245120"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0080761"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0091080"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116367"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0106977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093058"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/g.html\n",
        "0119173"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0177789"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083987"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0217505"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0113161"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0087332"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097428"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0172495"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0068646\n",
        "0120685"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0089212\n",
        "0119217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0089218"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0061722"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120689"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/h.html\n",
        "0113243"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0077651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0095271"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0146882"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0091203"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0110027"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119314"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0251736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/i.html"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0130018"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0210742"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0097576"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0082971"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0087469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0110148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0045917"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0038650"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/j.html\n",
        "0119396"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0073195"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0077766"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0085750"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0018037"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116695\n",
        "0099892"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0107290"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119567"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/k.html\n",
        "0104627"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0079417\n",
        "http://www.simplyscripts.com/l.html\n",
        "0104691"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0089469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0110413"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120735"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0116922"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0160484"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0011414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102357"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/m.html\n",
        "0066026"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0082694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0104797"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0113749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0125664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0025465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0110475"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0133093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119643\n",
        "0119654"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0151137\n",
        "0100157"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0244353"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0071853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0085959"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093565"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120616"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0119738\n",
        "0102492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0110613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0177023"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0132347"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/n.html"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0074958"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120770"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0048424"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0142688"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0058414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0125439\n",
        "http://www.simplyscripts.com/o.html\n",
        "0110737"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0054240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/p.html\n",
        "0019254"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102685"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093773"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0100405"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0093779"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/q.html"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/r.html"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0184858"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0086190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0178868"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102798"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0117500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0073629"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0029496"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0117509\n",
        "0163187"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0128445"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/s.html\n",
        "0047443"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120815"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0098258"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0017350"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0108052\n",
        "0117571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120082"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0134084"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0049730"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0114369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0138097"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0111149"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0083067"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102926"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0105417"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0167404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0108160"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0114478\n",
        "0094008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0069303"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120174"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0092005"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0098382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0102975"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0111280"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120844"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0076759"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0111300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120238"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0088206"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0081573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0086393"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0094074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0078346"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/t.html\n",
        "0088247"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0117880\n",
        "0103064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0103074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0084787"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0066434"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0120347"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0100802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0084827"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0153301\n",
        "0111503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0114746"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0105665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/uvw.html\n",
        "0084855"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0124198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0055601"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0046534"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0029747"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0161081"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0207201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0108558"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0118158"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0096446"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0090329"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0032138"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0143145"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "http://www.simplyscripts.com/xyz.html\n",
        "0120903"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0072431"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0128853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0080180"
       ]
      },
      {
       "ename": "OSError",
       "evalue": "[Errno 2] No such file or directory: 'output/0158983.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-a1e219ae2cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0mimdb_num_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_num_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#remove any duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m \u001b[0mgrab_rotten_tomatoes_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_num_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbox_office_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macademy_award_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-3-a1e219ae2cde>\u001b[0m in \u001b[0;36mgrab_rotten_tomatoes_info\u001b[0;34m(dataList, datafile, box_office_dict, academy_award_dict)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load a json string into a collection of lists and dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mimdb_id\u001b[0m \u001b[0;34m<>\u001b[0m \u001b[0;34m\"0000000\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m35000\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#if script is less than 35kb, disregard it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mrt_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jbencook/anaconda/lib/python2.7/genericpath.pyc\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: 'output/0158983.txt'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Exploratory Analysis </font></b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We envision tables of groupings of scripts that are similar to each other based on our classifications -- but that you wouldn\u2019t *think* would be necessarily similar on their own. The best predicted and worst predicted scripts  we will display along with their actual box office totals. We can do this effectively with a scatter plot for a multitude of scripts, or with a bar chart if we look at the top 10 predicted scripts and how they did, versus how we\u2019d think they\u2019d do.\n",
      "Simple histograms of the most common words in our scripts, the amount of dialogue that takes place (done by stripping out all words except the capitalized words -- all character names are capslocked so it\u2019s a good first order approximation to strip out everything but the capslock, removing extraneous scene setting and emphasis description words, and then see two character names next to each other which indicates the order in which they talk in the movie. We are taking advantage of what we know about the script formatting to do this.)\n",
      "\n",
      "Our final website will also bring into a greater context the extent to which we are successful at predicting a movie\u2019s success; for example, if we know that a movie was up against tough competition when it was released (like Antz of Dreamworks Animation vs. A Bug\u2019s Life by Pixar in the late 1990s), that also affects its performance. This final step will demonstrate how a combination of a technique such as ours, plus insider industry information, can be an effective of way of selecting scripts.\n",
      "\n",
      "To the best of our knowledge, none of what we have described is publically available and there appears to be scant industry interest in text analysis of movie scripts to date so it will be important that our website shows what we\u2019ve done in relation to any earlier attempts at script classification (of which the Gladwell New Yorker feature is an example of a proprietary technology; but that is done on a new script basis, not a meta-analysis of many scripts like we are doing.)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One method we can use is for seeing if we can predict the genre of the movie: Drama, Action-Adventure, Romance, etc. (as specified in Rotten Tomatoes) with a Naive Bayes classifier run on a bag of words, similar to how we predicted \u201cfreshness\u201d of movie reviews in the Bayesian Tomatoes homework assignment. We will experiment with hard class assignment and soft assignment. If we are successful at predicting genre, we will include the estimated genres as predictors in the movie success model. If we are unsuccessful at predicting genre we will use genre metadata from IMDB. The class of the movie should interact with the other features in order to predict box office success and critical acclaim.\n",
      "\n",
      "For the success model, we will use Latent Dirichlet Allocation to extract topics for each movie, the most important topics for each movie will also be considered features. We will use a collapsed Gibbs sampler to randomly assign each word in the corpus to one of the K topics. We use this as a dimension-reduction technique, so the proportion of tokens (words) in each topic is a real-valued feature that can be included in our Bayesian regression model.\n",
      "\n",
      "Other features include length of the script, number of characters, length of the longest monologue (as inferred by spacing between capitalized words), swear words, etc.\n",
      "\n",
      "We give each weight in the regression model a Normal prior whose variance is distributed Inverse Gamma, this allows for easy update rules for the weights that can be computed in closed form. We will determine other parameters, such as number of topics in the LDA model, initial values for hyperparameters, etc. through cross-validation of the final regression model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using topics to decide movie making\n",
      "\n",
      "Topics are important to us because they fall under what's called called the High Concept http://www.lettersofnote.com/2011/11/some-thoughts-on-our-business.html "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Speaking/dialogue histogram and statistics.\n",
      "\n",
      "Obtain a list of speakers in the script as well as the number of dialogues they have, and compute the histogram/summary statistics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Takes an IMDB number, reads in the file, and extracts speakers using regex.\n",
      "\"\"\"\n",
      "\n",
      "def extract_speakers(imdb_number):\n",
      "#     f = open(str(imbd_number)+'.txt', 'r')\n",
      "    f = open('output_v3/' + str(imdb_number) + '.txt', 'r')\n",
      "    speakers = []\n",
      "    for line in f.readlines():\n",
      "        m = re.match(r'\\s{20}(\\w+)', line.replace('\\t','    '))\n",
      "        if m:\n",
      "            speakers.append(m.group(1))\n",
      "    return speakers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Uses extract_speakers to get list of speakers, then returns set (i.e. unique character names).\n",
      "\"\"\"\n",
      "\n",
      "def get_characters(imdb_number):\n",
      "    return set(extract_speakers(imdb_number))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Gets number of 'lines' that each speaker has.\n",
      "\"\"\"\n",
      "\n",
      "def dialogue_count_dict(speaker_list, speaker_order):\n",
      "    \n",
      "    speaker_count = {}\n",
      "    \n",
      "    for speaker in speaker_list:\n",
      "        speaker_count[speaker] = len([char for char in speaker_order if char == speaker])\n",
      "        \n",
      "    return speaker_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "This function returns a sorted list of tuples, from top listed speaker to bottom, to predict main characters in a film.\n",
      "By picking the distribution of speaking roles this could be an input to predict what genre the movie is in.\n",
      "\"\"\"\n",
      "\n",
      "import operator\n",
      "\n",
      "def dialogue_count_dict_sorted(dialoguecount):\n",
      "    return sorted(dialoguecount.iteritems(), key = operator.itemgetter(1), reverse = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function for creating histogram from JUST IMDB number using all functions we defined above.\n",
      "Also computes mean, variance, and standard deviation and saves as txt.\n",
      "\"\"\"\n",
      "\n",
      "def generate_histogram(imdb_number):\n",
      "    # Create ordered dictionary-list of dialogue counts.\n",
      "    dialogue_count = dialogue_count_dict(get_characters(imdb_number), extract_speakers(imdb_number))\n",
      "    ordered_list = dialogue_count_dict_sorted(dialogue_count)\n",
      "    \n",
      "    # Get list of names and values.\n",
      "    names = []\n",
      "    values = []\n",
      "    for speaker in ordered_list:\n",
      "        names.append(speaker[0])\n",
      "        values.append(speaker[1])\n",
      "    \n",
      "    # Compute mean, variance, standard deviation.\n",
      "    with open(str(imdb_number) + \"_charhist.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(values)))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    axislimits = [0, max(values)+0.1*max(values), 0, len(values)]\n",
      "    figure = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(values)), values)\n",
      "    plt.title('Histogram of How Much Characters Talk')\n",
      "    plt.xlabel('Number of Dialogues')\n",
      "    plt.ylabel('Speakers')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(names)),names)\n",
      "    plt.rc('ytick', labelsize=13)\n",
      "    plt.show()\n",
      "    figure.savefig(str(imdb_number) + '.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Interactions histograms and statistics.\n",
      "\n",
      "We take an IMDB number, extract the list of characters and the order in which the characters speak. We then take each switch between speakers as defining an interaction, and calculate the interactions between pairs of characters, also obtaining the mean, variance, and standard deviation of these histograms.\n",
      "\n",
      "These summary statistics are then used among all the files to generate histograms of the distribution of means and standard deviations among all movies on our list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function that again takes imdb_number and generates histogram of interactions, saves as png.\n",
      "Added functionality: computes mean, variance, standard deviation of histogram, saves as txt.\n",
      "\"\"\"\n",
      "\n",
      "def compute_interactions(imdb_number):\n",
      "    # Create list of actual, nonzero pairs.\n",
      "    speaker_list = get_characters(imdb_number)\n",
      "    speaker_order = extract_speakers(imdb_number)\n",
      "    pairs = {}\n",
      "    for i in xrange(len(speaker_order)-1):\n",
      "        if speaker_order[i] > speaker_order[i+1]:\n",
      "            try:\n",
      "                pairs[speaker_order[i+1],speaker_order[i]] += 1\n",
      "            except:\n",
      "                pairs[speaker_order[i+1],speaker_order[i]] = 1\n",
      "        elif speaker_order[i] < speaker_order[i+1]:\n",
      "            try:\n",
      "                pairs[speaker_order[i],speaker_order[i+1]] += 1\n",
      "            except:\n",
      "                pairs[speaker_order[i],speaker_order[i+1]] = 1\n",
      "    \n",
      "    # Sort and get values.\n",
      "    ordered_pairs = sorted(pairs.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
      "    names = []\n",
      "    values = []\n",
      "    for speakers, count in ordered_pairs:\n",
      "        names.append(speakers)\n",
      "        values.append(count)\n",
      "    \n",
      "    # Compute mean, variance, standard deviation.\n",
      "    with open(str(imdb_number) + \"_interhist.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(values)))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    axislimits = [0, max(values)+0.1*max(values), 0, len(values)]\n",
      "    figure = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(values)), values)\n",
      "    plt.title('Histogram of How Much Characters Interact in Dialogue')\n",
      "    plt.xlabel('Number of Interactions')\n",
      "    plt.ylabel('Speaker Pairs')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(names)),names)\n",
      "    plt.rc('ytick', labelsize=13)\n",
      "    plt.show()\n",
      "    figure.savefig(str(imdb_number) + '_inter.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compute histogram of actual words spoken.\n",
      "\n",
      "Rather than compute the number of dialogues by the characters, do a more fine-grained analysis by using regex to get the number of words in each dialogue and make histograms/summary statistics of these items."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Takes an IMDB number, reads in the file, and extracts speakers + line numbers using regex, getting a tuple.\n",
      "\"\"\"\n",
      "\n",
      "def get_lines(imdb_number):\n",
      "    f = open(str(imdb_number)+'.txt', 'r')\n",
      "    \n",
      "    # Get list of line numbers for start of each quote\n",
      "    line_numbers = []\n",
      "    count = 1\n",
      "    for line in f.readlines():\n",
      "        m = re.match(r'^\\s{20}(\\w+.*)\\r$', line)\n",
      "        if m:\n",
      "            line_numbers.append((m.group(1), count))\n",
      "        count += 1\n",
      "\n",
      "    return line_numbers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Takes an IMDB number and returns actual text of lines per speaker using regex and some clever file reading, getting a tuple.\n",
      "\"\"\"\n",
      "\n",
      "def get_speaker_lines(imdb_number):\n",
      "    lines = get_lines(imdb_number)\n",
      "    speaker_lines = []\n",
      "    line_numbers = []\n",
      "    for speaker, number in lines:\n",
      "        speaker_lines.append((speaker,[]))\n",
      "        line_numbers.append(number)\n",
      "    \n",
      "    f = open(str(imdb_number)+'.txt', 'r')\n",
      "    speaker_count = 0\n",
      "    count = 1\n",
      "    for line in f:\n",
      "        if count in line_numbers:\n",
      "            while True:\n",
      "                nextline = f.next()\n",
      "                count += 1\n",
      "                if re.match(r'^\\r\\n$', nextline):\n",
      "                    break\n",
      "                speaker_lines[speaker_count][1].append(nextline.strip())\n",
      "            speaker_count += 1\n",
      "        count += 1\n",
      "    \n",
      "    return [(speaker, \" \".join(linelist)) for speaker, linelist in speaker_lines]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Uses get_speaker_lines to get the lines list for IMDB number, then computes the word counts, means, variance, std, and histogram.\n",
      "\"\"\"\n",
      "\n",
      "def compute_line_counts(imdb_number):\n",
      "    speaker_lines = get_speaker_lines(imdb_number)\n",
      "    speakers = []\n",
      "    speaker_counts = []\n",
      "    for speaker, line in speaker_lines:\n",
      "        speakers.append(speaker)\n",
      "        speaker_counts.append((speaker, len(line.split())))\n",
      "    \n",
      "    # Compute total and average word count per speaker.\n",
      "    counts_dict = {}\n",
      "    avg_counts = {}\n",
      "    for speaker in speakers:\n",
      "        counts_dict[speaker] = 0\n",
      "        avg_counts[speaker] = 0\n",
      "        number = 0\n",
      "        for name, count in speaker_counts:\n",
      "            if name == speaker:\n",
      "                counts_dict[speaker] += count\n",
      "                number += 1\n",
      "        avg_counts[speaker] = float(counts_dict[speaker]) / float(number)\n",
      "        \n",
      "    # Sort and get values for both total and average counts.\n",
      "    ordered_total = sorted(counts_dict.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
      "    ordered_avg = sorted(avg_counts.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
      "    total_names = []\n",
      "    total_values = []\n",
      "    avg_names = []\n",
      "    avg_values = []\n",
      "    for name, count in ordered_total:\n",
      "        total_names.append(name)\n",
      "        total_values.append(count)\n",
      "    for name, count in ordered_avg:\n",
      "        avg_names.append(name)\n",
      "        avg_values.append(count)\n",
      "    \n",
      "    # Compute mean, variance, standard deviation.\n",
      "    with open(str(imdb_number) + \"_totalwc.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(total_values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(total_values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(total_values)))\n",
      "    \n",
      "    with open(str(imdb_number) + \"_avgwc.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(avg_values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(avg_values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(avg_values)))\n",
      "    \n",
      "    # Plot histograms and save accordingly.\n",
      "    axislimits = [0, max(values)+0.1*max(values), 0, len(total_values)]\n",
      "    figure1 = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(total_values)), total_values)\n",
      "    plt.title('Histogram of Total Word Counts of Lines')\n",
      "    plt.xlabel('Total Word Count')\n",
      "    plt.ylabel('Speaker')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(total_names)), total_names)\n",
      "    plt.rc('ytick', labelsize=13)\n",
      "    plt.show()\n",
      "    figure1.savefig(str(imdb_number) + '_totalwc.png')\n",
      "    \n",
      "    axislimits = [0, max(avg_values), 0, len(avg_values)]\n",
      "    figure2 = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(avg_values)), avg_values)\n",
      "    plt.title('Histogram of Average Word Counts of Lines')\n",
      "    plt.xlabel('Average Word Count')\n",
      "    plt.ylabel('Speaker')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(avg_names)), avg_names)\n",
      "    plt.rc('ytick', labelsize=13)\n",
      "    plt.show()\n",
      "    figure2.savefig(str(imdb_number) + '_avgwc.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exploratory data analysis on script metadata.\n",
      "\n",
      "We conduct an extensive exploratory data analysis on the metadata available on the scripts in our database, which includes data such as:\n",
      "\n",
      "- Genre\n",
      "- Critics Score\n",
      "- Audience Score\n",
      "- Audience Rating\n",
      "- Critics Rating\n",
      "- Runtime\n",
      "- Year\n",
      "- Main 5 Actors\n",
      "- Budget\n",
      "- Gross Revenues\n",
      "- Oscar Wins\n",
      "- Oscar Nominations\n",
      "\n",
      "This data is used to create histograms, summary statistics, and other visualizations for use in predictive analysis.\n",
      "\n",
      "See Supplementary References for peer reviewed literature on Box Office prediction and performance which guided us in which features to consider. We didn\u2019t take into account release time or sequels, which is perhaps why our model is good but not great at predicting the final movie outcome (note that we encountered papers that were unable to get any correlation in a Box Office prediction model altogether, so our script feature approach is a tremendous success compared to alternative methodologies in the past.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import pandas\n",
      "\n",
      "\"\"\"\n",
      "Open the master list of metadata as TSV, and store data as Pandas dataframe for analysis.\n",
      "\"\"\"\n",
      "def open_master(master_file):\n",
      "    return pd.read_table(master_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "masterfile = open_master('MasterList_v3.tsv')\n",
      "genres = [\"Action & Adventure\",\"Animation\",\"Art House & International\",\"Classics\",\"Comedy\",\"Cult Movies\",\"Documentary\",\n",
      "          \"Drama\",\"Horror\",\"Kids & Family\",\"Musical & Performing Arts\",\"Mystery & Suspense\",\"Romance\",\"Science Fiction & Fantasy\",\n",
      "          \"Special Interest\",\"Television\",\"Western\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of genres.\n",
      "\"\"\"\n",
      "\n",
      "def compute_genres(masterfile, genres):\n",
      "    # Compute total number of movies in each genre.\n",
      "    total_counts = {}\n",
      "    for genre in genres:\n",
      "        total_counts[genre] = 0\n",
      "        for count in masterfile[genre]:\n",
      "            total_counts[genre] += int(count)\n",
      "    \n",
      "    # Generate bar plot data sets.\n",
      "    names = []; values = []\n",
      "    for genre, count in total_counts.iteritems():\n",
      "        names.append(genre)\n",
      "        values.append(count)\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_genres_stat.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(values)))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    axislimits = [0, max(values)+0.1*max(values), 0, len(values)]\n",
      "    figure = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(values)), values)\n",
      "    plt.title('Histogram of Genre Totals')\n",
      "    plt.xlabel('Number of Movies')\n",
      "    plt.ylabel('Genres')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(names)),names)\n",
      "    plt.rc('ytick', labelsize=10)\n",
      "    plt.show()\n",
      "    figure.savefig('masterlist_genres_hist.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_genres(masterfile, genres)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of MPAA ratings.\n",
      "\"\"\"\n",
      "\n",
      "def compute_ratings(masterfile, mpaa = \"mpaa_rating\"):\n",
      "    # Compute total number of movies in each rating.\n",
      "    ratings = set(masterfile[mpaa])\n",
      "    total_counts = {}\n",
      "    for rating in ratings:\n",
      "        total_counts[rating] = sum([1 for row in masterfile[mpaa] if row == rating])\n",
      "    \n",
      "    # Generate bar plot data sets.\n",
      "    names = []; values = []\n",
      "    for rating, count in total_counts.iteritems():\n",
      "        names.append(rating)\n",
      "        values.append(count)\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_ratings_stat.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(values)))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    axislimits = [0, max(values)+0.1*max(values), 0, len(values)]\n",
      "    figure = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(values)), values)\n",
      "    plt.title('Histogram of MPAA Ratings Totals')\n",
      "    plt.xlabel('Number of Movies')\n",
      "    plt.ylabel('MPAA Ratings')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(names)),names)\n",
      "    plt.rc('ytick', labelsize=10)\n",
      "    plt.show()\n",
      "    figure.savefig('masterlist_ratings_hist.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_ratings(masterfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of years.\n",
      "\"\"\"\n",
      "\n",
      "def compute_years(masterfile, year_cat = \"year\"):\n",
      "    # Compute total number of movies in each year.\n",
      "    years = set(masterfile[year_cat])\n",
      "    total_counts = {}\n",
      "    for year in years:\n",
      "        total_counts[year] = sum([1 for row in masterfile[year_cat] if row == year])\n",
      "    \n",
      "    # Generate bar plot data sets.\n",
      "    total_counts = sorted(total_counts.iteritems(), key = operator.itemgetter(0), reverse = True)\n",
      "    names = []; values = []\n",
      "    for year, count in total_counts:\n",
      "        names.append(year)\n",
      "        values.append(count)\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_years_stat.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(values)))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    axislimits = [0, max(values)+0.1*max(values), 0, len(values)]\n",
      "    figure = plt.figure(figsize=(20,20))\n",
      "    plt.barh(range(len(values)), values)\n",
      "    plt.title('Histogram of Annual Movie Totals')\n",
      "    plt.xlabel('Number of Movies')\n",
      "    plt.ylabel('Year')\n",
      "    plt.axis(axislimits)\n",
      "    plt.yticks(range(len(names)),names)\n",
      "    plt.rc('ytick', labelsize=10)\n",
      "    plt.show()\n",
      "    figure.savefig('masterlist_years_hist.png')\n",
      "    \n",
      "    # Plot scatterplot and save.\n",
      "    figure2 = plt.figure(figsize=(10,10))\n",
      "    plt.scatter(names, values)\n",
      "    plt.title('Histogram of Annual Movie Totals')\n",
      "    plt.xlabel('Number of Movies')\n",
      "    plt.ylabel('Year')\n",
      "    figure2.savefig('masterlist_years_scatter.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_years(masterfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of runtimes.\n",
      "\"\"\"\n",
      "\n",
      "def compute_runtimes(masterfile, runtime = \"runtime\"):\n",
      "    values = [int(runtime) for runtime in masterfile[runtime] if runtime != '' and not pd.isnull(runtime)]\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_runtime_stat.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean: {}\\n\".format(np.mean(values)))\n",
      "        text_file.write(\"Variance: {}\\n\".format(np.var(values)))\n",
      "        text_file.write(\"Standard Variation: {}\\n\".format(np.std(values)))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    hist, bin_edges = np.histogram(values, bins = range(0,250,10))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = 10)\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Movie Runtimes')\n",
      "    plt.xlabel('Number of Movies')\n",
      "    plt.ylabel('Runtime')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_runtimes_hist.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_runtimes(masterfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of critic scores.\n",
      "\"\"\"\n",
      "\n",
      "def compute_runtimes(masterfile, critics = [\"Critics Score\", \"Audience Score\", \"Audience Rating\", \"Critics Rating\"]):\n",
      "    critics_dict = {}\n",
      "    for critic in critics:\n",
      "        if critic == \"Critics Score\" or critic == \"Audience Score\":\n",
      "            critics_dict[critic] = [int(score) for score in masterfile[critic] if score != '']\n",
      "        elif critic == \"Audience Rating\":\n",
      "            critics_dict[critic] = [1 if score == 'Upright' else 0 for score in masterfile[critic]]\n",
      "        else:\n",
      "            critics_dict[critic] = [0 if score == 'Rotten' else 1 if score == 'Fresh' else 2 for score in masterfile[critic]]\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_critics_stat.txt\", \"w\") as text_file:\n",
      "        for critic in critics:\n",
      "            text_file.write(\"Mean (\" + critic + \"): {}\\n\".format(np.mean(critics_dict[critic])))\n",
      "            text_file.write(\"Variance (\" + critic + \"): {}\\n\".format(np.var(critics_dict[critic])))\n",
      "            text_file.write(\"Standard Variation (\" + critic + \"): {}\\n\".format(np.std(critics_dict[critic])))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    figure, axarr = plt.subplots(2, 2)\n",
      "    hist, bin_edges = np.histogram(critics_dict[\"Critics Score\"], bins = range(0, 110, 10))\n",
      "    axarr[0, 0].bar(bin_edges[:-1], hist, width = 10)\n",
      "    axarr[0, 0].set_title('Critics Score Histogram')\n",
      "    \n",
      "    hist, bin_edges = np.histogram(critics_dict[\"Audience Score\"], bins = range(0, 110, 10))\n",
      "    axarr[0, 1].bar(bin_edges[:-1], hist, width = 10)\n",
      "    axarr[0, 1].set_title('Audience Score Histogram')\n",
      "    \n",
      "    values = [sum(critics_dict[\"Audience Rating\"]), len(critics_dict[\"Audience Rating\"]) - sum(critics_dict[\"Audience Rating\"])]\n",
      "    axarr[1, 0].bar(np.arange(-0.5, len(values)-1, 1), values, width = 1)\n",
      "    axarr[1, 0].set_title('Audience Rating Histogram')\n",
      "    \n",
      "    values = [sum([1 if score == 2 else 0 for score in critics_dict[\"Critics Rating\"]]),\n",
      "              sum([1 if score == 1 else 0 for score in critics_dict[\"Critics Rating\"]]),\n",
      "              sum([1 if score == 0 else 0 for score in critics_dict[\"Critics Rating\"]])]\n",
      "    axarr[1, 1].bar(np.arange(-0.5,len(values)-1,1), values, width = 1)\n",
      "    axarr[1, 1].set_title('Critics Rating Histogram')\n",
      "    figure.savefig('masterlist_critics_hist.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_runtimes(masterfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of budgets, gross revenues, and correlations.\n",
      "\"\"\"\n",
      "\n",
      "def compute_budget_gross(masterfile, budget = \"Budget\", gross = \"Gross\"):\n",
      "    quantities = {}\n",
      "    for quantity in [budget, gross]:\n",
      "        quantities[quantity] = []\n",
      "    for index, row in masterfile[[budget, gross]].iterrows():\n",
      "        if row[budget] != '' and row[gross] != '' and \\\n",
      "        not pd.isnull(row[budget]) and not pd.isnull(row[gross]):\n",
      "            quantities[budget].append(int(row[0]))\n",
      "            quantities[gross].append(int(row[1]))\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_budget_stat.txt\", \"w\") as text_file:\n",
      "        for quantity in [budget, gross]:\n",
      "            text_file.write(\"Mean (\" + quantity + \"): {}\\n\".format(np.mean(quantities[quantity])))\n",
      "            text_file.write(\"Variance (\" + quantity + \"): {}\\n\".format(np.var(quantities[quantity])))\n",
      "            text_file.write(\"Standard Variation (\" + quantity + \"): {}\\n\".format(np.std(quantities[quantity])))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    hist, bin_edges = np.histogram(quantities[budget], bins = range(0,max(quantities[budget]),int(0.05*max(quantities[budget]))))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = int(0.05*max(quantities[budget])))\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Movie Budgets')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Budget Amount ($)')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_budgets_hist.png')\n",
      "    \n",
      "    hist, bin_edges = np.histogram(quantities[gross], bins = range(0,max(quantities[gross]),int(0.05*max(quantities[gross]))))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = int(0.05*max(quantities[gross])))\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Movie Gross Revenues')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Gross Revenues ($)')\n",
      "    plt.show()\n",
      "    figure.savefig('masterlist_gross_hist.png')\n",
      "    \n",
      "    # Plot scatterplot of budgets to gross amounts.\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.scatter(quantities[budget], quantities[gross])\n",
      "    plt.title('Scatterplot of Budget to Gross Revenues')\n",
      "    plt.ylabel('Gross Revenues ($)')\n",
      "    plt.xlabel('Budget Amount ($)')\n",
      "    plt.plot(range(0, max(quantities[budget]),int(0.01*max(quantities[budget]))), \n",
      "             range(0, max(quantities[budget]),int(0.01*max(quantities[budget]))))\n",
      "    plt.show()\n",
      "    figure.savefig('masterlist_amount_scatter.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_budget_gross(masterfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Computes overall distribution of budgets, gross revenues, and correlations.\n",
      "\"\"\"\n",
      "\n",
      "def compute_oscars(masterfile, nominations = \"Oscar Nominations\", awards = \"Oscar Wins\"):\n",
      "    oscars = {}\n",
      "    for quantity in [nominations, awards]:\n",
      "        oscars[quantity] = [int(count) for count in masterfile[quantity]]\n",
      "    \n",
      "    # Summary statistics.\n",
      "    with open(\"masterlist_oscars_stat.txt\", \"w\") as text_file:\n",
      "        for quantity in [nominations, awards]:\n",
      "            text_file.write(\"Mean (\" + quantity + \"): {}\\n\".format(np.mean(oscars[quantity])))\n",
      "            text_file.write(\"Variance (\" + quantity + \"): {}\\n\".format(np.var(oscars[quantity])))\n",
      "            text_file.write(\"Standard Variation (\" + quantity + \"): {}\\n\".format(np.std(oscars[quantity])))\n",
      "    \n",
      "    # Plot histogram and save accordingly.\n",
      "    hist, bin_edges = np.histogram(oscars[nominations], bins = range(0,max(oscars[nominations])+1,1))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Oscar Nominations')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Number of Nominations')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_oscarsnom_hist.png')\n",
      "    \n",
      "    hist, bin_edges = np.histogram(oscars[awards], bins = range(0,max(oscars[awards])+1,1))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Oscar Nominations')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Number of Nominations')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_oscarsawards_hist.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_oscars(masterfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compute global histogram and summary statistics of character interactions.\n",
      "\n",
      "Compute statistics for character interactions for each script, and coalesce into global histogram and summary statistics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function that again takes imdb_number and generates histogram of interactions, saves as png.\n",
      "Added functionality: computes mean, variance, standard deviation of histogram, saves as txt.\n",
      "\"\"\"\n",
      "\n",
      "def compute_inter(imdb_number):\n",
      "    # Create list of actual, nonzero pairs.\n",
      "    speaker_order = extract_speakers(imdb_number)\n",
      "    speaker_list = set(speaker_order)\n",
      "    pairs = {}\n",
      "    for i in xrange(len(speaker_order)-1):\n",
      "        if speaker_order[i] > speaker_order[i+1]:\n",
      "            try:\n",
      "                pairs[speaker_order[i+1],speaker_order[i]] += 1\n",
      "            except:\n",
      "                pairs[speaker_order[i+1],speaker_order[i]] = 1\n",
      "        elif speaker_order[i] < speaker_order[i+1]:\n",
      "            try:\n",
      "                pairs[speaker_order[i],speaker_order[i+1]] += 1\n",
      "            except:\n",
      "                pairs[speaker_order[i],speaker_order[i+1]] = 1\n",
      "    \n",
      "    # Sort and get values.\n",
      "    ordered_pairs = sorted(pairs.iteritems(), key = operator.itemgetter(1), reverse = True)\n",
      "    values = [pair[1] for pair in ordered_pairs]\n",
      "#     print speaker_list\n",
      "    \n",
      "    # Compute mean, variance, standard deviation.\n",
      "    return (np.mean(values), np.var(values), np.std(values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Compute global means, variance, standard deviations of individual means, var, std; then print histogram and save summary stats.\n",
      "\"\"\"\n",
      "\n",
      "def compute_global_inter():\n",
      "\n",
      "    global_means = []; global_var = []; global_std = []\n",
      "    ind_mean = 0\n",
      "\n",
      "    for index, file_name in enumerate(glob.glob(\"output_v3/*.txt\")):\n",
      "        imdb_number = ((file_name.split('/'))[1].split('.'))[0] # Extract imdb_number from file name\n",
      "        (ind_mean, ind_var, ind_std) = compute_inter(imdb_number)\n",
      "        if not math.isnan(ind_mean):\n",
      "            global_means.append(ind_mean)\n",
      "        if not math.isnan(ind_var):\n",
      "            global_var.append(ind_var)\n",
      "        if not math.isnan(ind_std):\n",
      "            global_std.append(ind_std)\n",
      "        if index % 30 == 0:\n",
      "            print index\n",
      "            print ind_mean, ind_var, ind_std\n",
      "    \n",
      "    print len(global_means), len(global_var), len(global_std)\n",
      "  \n",
      "    # Save summary global statistics.\n",
      "    with open(\"masterlist_global_inter_stat.txt\", \"w\") as text_file:\n",
      "        text_file.write(\"Mean (Ind. Mean): {}\\n\".format(np.mean(global_means)))\n",
      "        text_file.write(\"Variance (Ind. Mean): {}\\n\".format(np.var(global_means)))\n",
      "        text_file.write(\"Standard Variation (Ind. Mean): {}\\n\\n\".format(np.std(global_means)))\n",
      "        \n",
      "        text_file.write(\"Mean (Ind. Var.): {}\\n\".format(np.mean(global_var)))\n",
      "        text_file.write(\"Variance (Ind. Var.): {}\\n\".format(np.var(global_var)))\n",
      "        text_file.write(\"Standard Variation (Ind. Var.): {}\\n\\n\".format(np.std(global_var)))\n",
      "        \n",
      "        text_file.write(\"Mean (Ind. Std.): {}\\n\".format(np.mean(global_std)))\n",
      "        text_file.write(\"Variance (Ind. Std.): {}\\n\".format(np.var(global_std)))\n",
      "        text_file.write(\"Standard Variation (Ind. Std.): {}\\n\\n\".format(np.std(global_std)))\n",
      "    \n",
      "    # Compute global histograms and save.\n",
      "    hist, bin_edges = np.histogram(global_means, bins = range(0,int(max(global_means))+1,1))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Average Character Interactions')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Number of Interactions')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_global_inter_means.png')\n",
      "    \n",
      "    hist, bin_edges = np.histogram(global_var, bins = range(0,int(max(global_var))+100,100))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = 100)\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Variances in Character Interactions')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Number of Interactions (Squared)')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_global_inter_var.png')\n",
      "    \n",
      "    hist, bin_edges = np.histogram(global_std, bins = range(0,int(max(global_std))+3,3))\n",
      "    figure = plt.figure(figsize=(10,10))\n",
      "    plt.bar(bin_edges[:-1], hist, width = 3)\n",
      "    plt.xlim(min(bin_edges), max(bin_edges))\n",
      "    plt.ylim(0, max(hist) + 0.1 * max(hist))\n",
      "    plt.title('Histogram of Standard Deviations in Character Interactions')\n",
      "    plt.ylabel('Number of Movies')\n",
      "    plt.xlabel('Number of Interactions')\n",
      "    plt.show()   \n",
      "    figure.savefig('masterlist_global_inter_std.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_global_inter()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Final Analysis </font></b>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Utilities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def open_file(imbd_number):\n",
      "    \"\"\"\n",
      "    Opens text file with IMBD Number, which we should make a string.\n",
      "    Returns the raw words of the script, with punctuation.\n",
      "    \"\"\"\n",
      "    f = open(str(imbd_number)+'.txt', 'r')\n",
      "    raw_text = []\n",
      "    for line in f.readlines():\n",
      "        raw_text += [word for word in line.split() if len(word) > 0]\n",
      "    return raw_text\n",
      "\n",
      "\n",
      "def remove_uppercase(split_text):\n",
      "    \"\"\"\n",
      "    Takes script in raw word-list form and returns the upper case words\n",
      "    \"\"\"\n",
      "    sans_upper = []\n",
      "    for word in split_text:\n",
      "        if not word.isupper():\n",
      "            sans_upper.append(word)\n",
      "    return sans_upper\n",
      "\n",
      "def word_strip(text, stoplist, scrabble):\n",
      "    \"\"\"\n",
      "    Strips out punctuation from uppercase words and returns them.\n",
      "    I've kept them uppercase in case slam them back together w/ lowercase words (so they're identifiable as such.)\n",
      "    \"\"\"\n",
      "    wl = []\n",
      "    for word in text:\n",
      "        word = (\"\".join([char for char in word if char.isalpha()])).lower()\n",
      "        if len(word) > 0 and word not in stoplist and word in scrabble:\n",
      "            wl.append(word)\n",
      "    return wl\n",
      "\n",
      "def get_symmetric_dif(corp):\n",
      "    \"\"\"\n",
      "    Return the set of words that are unique to one script in the corpus\n",
      "    \"\"\"\n",
      "    corpus = corp[:]\n",
      "    corpus = map(itemgetter(1), corpus)\n",
      "    symm_diff = set(corpus[0])\n",
      "    for i in xrange(1,len(corpus)):\n",
      "        symm_diff.symmetric_difference_update(set(corpus[i]))\n",
      "    return symm_diff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After scraping the scripts, they get sent to '.txt' files in an output folder. Because the data were subject to change as our web scraping code evolved, it was important to be able to read in all of the scripts quickly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt_scripts = !ls ../output_v3/\n",
      "imdb_nums = [script[:-4] for script in txt_scripts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each script requires a significant amount of preprocessing in order to obtain LDA results that make sense. First, we want to remove names from the script as these should not be considered meaningful aspects of topics that distinguish between movies. A simple list of first and last names (but only the 25 most popular American last names) are added to our stoplist and thus not included in the scripts that our analyzed. We also removed a large number of prepositions and other stop words such as 'a', 'and', 'the', etc. Finally, we only included words that are found in a Scrabble dictionary in order to remove other proper nouns that would not meaningfully distinguish between topics. The reason it was necessary to remove names and to check against a Scrabble dictionary is that many names are also English words, for example, bob, dick, smith, and cook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stoplist = set(open('stopwords.txt', 'r').read().strip().split(','))\n",
      "\n",
      "names = np.loadtxt('names.txt', dtype=str)[:,0]\n",
      "names = set([name.lower() for name in names])\n",
      "possessive = set()\n",
      "for name in names:\n",
      "    possessive.add(name + 's')\n",
      "    \n",
      "names = names.union(possessive)\n",
      "    \n",
      "lastnames = np.loadtxt('lastnames.txt', dtype=str)[:,0]\n",
      "lastnames = set([name.lower() for name in lastnames])\n",
      "possessive = set()\n",
      "for name in lastnames:\n",
      "    possessive.add(name + 's')\n",
      "\n",
      "lastnames = lastnames.union(possessive)\n",
      "\n",
      "f = open('prepositions.txt', 'r')\n",
      "preps1 = f.readline().strip()\n",
      "preps1 = set(re.sub('<[^>]*>', ' ', preps1).split())\n",
      "\n",
      "f.readline()\n",
      "preps2 = f.readline().strip()\n",
      "preps2 = set(preps2.split(','))\n",
      "f.close()\n",
      "\n",
      "stoplist = stoplist.union(names)\n",
      "stoplist = stoplist.union(lastnames)\n",
      "stoplist = stoplist.union(preps1)\n",
      "stoplist = stoplist.union(preps2)\n",
      "\n",
      "scrab_file = open('dictionary.txt', 'r')\n",
      "scrabble = set([word.strip().lower() for word in scrab_file])\n",
      "\n",
      "raw_corpus = [(imdb, open_file('output_v3/%s' % imdb)) for imdb in imdb_nums]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our corpus data structure is a list of tuples where the first element is the imdb number and the second element is the lowercase words of the script (sans stop words). We needed to include the imbdb number because part of generating the corpus was removing scripts with fewer than 100 words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [[script[0], remove_uppercase(script[1])] for script in raw_corpus]\n",
      "corpus = [script for script in corpus if len(script[1]) > 100]\n",
      "corpus = [[script[0],word_strip(script[1], stoplist, scrabble)] for script in corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we removed words that only occur in one script. Although it was not possible to completely avoid the scenario of a single topic representing a single movie, removing words that are unique to one movie helped prevent this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sd = get_symmetric_dif(corpus)\n",
      "for i,script in enumerate(corpus):\n",
      "    corpus[i][1] = [word for word in script[1] if word not in sd]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After running LDA several times with the above preprocessing steps, it becamse clear that many topics were still being represented by very common words. To avoid this we decided to plot the number of occurrences for each word and then remove the words that occur 'much more frequently' than most words. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_dictionary = {}\n",
      "for script in corpus:\n",
      "    for word in script[1]:\n",
      "        if word in word_dictionary:\n",
      "            word_dictionary[word] += 1\n",
      "        else:\n",
      "            word_dictionary[word] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = word_dictionary.values()\n",
      "counts = sorted(counts, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(counts)\n",
      "remove_border()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After looking at the above plot, 3,000 occurrences was chosen as a suitable cutoff. Any word that occurs more than 3,000 times in our corpus is removed before LDA."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_too_frequent(cutoff, word_dictionary):\n",
      "    too_frequent = set()\n",
      "    for word in word_dictionary:\n",
      "        if word_dictionary[word] > cutoff:\n",
      "            too_frequent.add(word)\n",
      "    return too_frequent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf = get_too_frequent(3000, word_dictionary)\n",
      "for i,script in enumerate(corpus):\n",
      "    corpus[i][1] = [word for word in script[1] if word not in tf]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After removing singleton words and words that occur too frequently, the minimum length of a script is less than 100, but this was deemed to be acceptable since so many words had been removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lengths = [len(s[1]) for s in corpus]\n",
      "min(lengths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we plot the distribution of script lengths."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "plt.hist(lengths, normed=True, bins=50)\n",
      "remove_border()\n",
      "plt.ylabel('relative frequency')\n",
      "plt.xlabel('script length')\n",
      "fig.savefig('script_length_distro.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we use the gensim package to perform Latent Dirichlet Allocation (LDA) on the corpus to discover the 50 topics. LDA provides a generative model of text creation (Blei, Ng and Jordan, 2003):\n",
      "\n",
      "- A document is a vector of words: $\\mathbf{w} = [w_1, w_2,\\ldots,w_N]$, where $w_i$ is the $i^{\\textrm{th}}$ word in the sequence.\n",
      "- A corpus is a collection of $M$ documents: $D = [\\mathbf{w}_1, \\mathbf{w}_2, \\ldots, \\mathbf{w}_M]$\n",
      "\n",
      "To generate a document:\n",
      "\n",
      "- Choose $\\theta \\sim \\textrm{Dirichlet}(\\boldsymbol{\\alpha})$\n",
      "- For each word in $\\mathbf{w}$:\n",
      "    - Choose a topic: $z_i \\sim \\textrm{Multinomial}(\\theta)$\n",
      "    - Each topic is a distribution over words, meaning that we pick a word $w_i \\sim \\textrm{Multinomial}(\\mathbf{p}_{z_i})$\n",
      "\n",
      "\n",
      "\n",
      "After taking at how topics are distributed in our corpus, we use topics as a feature in our regression analyses. With our 50 topics, each script gets a score for each topic between 0 and 1 indicating the proportion of the script that was generated form a given topic. These are considered numerical features and help us predict genre and box office success."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scripts = map(itemgetter(1), corpus)\n",
      "dictionary = gensim.corpora.Dictionary(scripts)\n",
      "\n",
      "gensim_corpus = [dictionary.doc2bow(text) for text in scripts]\n",
      "gensim.corpora.MmCorpus.serialize('corpus.mm', gensim_corpus) # store to disk, for later use\n",
      "mm = gensim.corpora.MmCorpus('corpus.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = gensim.models.ldamodel.LdaModel(corpus=mm, \n",
      "                                      id2word=dictionary, \n",
      "                                      num_topics=50, \n",
      "                                      update_every=1, \n",
      "                                      chunksize=10000, \n",
      "                                      passes=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topics_top_ten = lda.print_topics(topics=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def topic_extractor(topics):\n",
      "    '''\n",
      "    Take output from LdaModel() and print the top ten words for each topic.\n",
      "    '''\n",
      "    cleaned = []\n",
      "    for t in topics:\n",
      "        clean = []\n",
      "        for word in t.split():\n",
      "            good_word = ''.join([letter for letter in word if letter.isalpha()])\n",
      "            if len(good_word) > 0:\n",
      "                clean.append(good_word)\n",
      "        cleaned.append(clean)\n",
      "    return cleaned"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topics = topic_extractor(topics_top_ten)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(50):\n",
      "    print 'Topic %d' %i\n",
      "    print '--------'\n",
      "    for word in topics[i]:\n",
      "        print word\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we create dictionaries in order to extract features for further analysis:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corp_dict = {}\n",
      "gensim_dict = {}\n",
      "script_len = {}\n",
      "topic_features = {}\n",
      "\n",
      "for i in xrange(len(corpus)):\n",
      "    ID, script = corpus[i]\n",
      "    gensim = gensim_corpus[i]\n",
      "    corp_dict[ID] = script\n",
      "    gensim_dict[ID] = gensim\n",
      "    script_len[ID] = len(script)\n",
      "    topic_features[ID] = lda[gensim]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We do some data munging to get the pandas dataframe in shape and to extract columns from the dataframe for regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read in the data collected from the web scraper\n",
      "data = pd.read_table('../MasterList_v3.tsv')\n",
      "data['IMDB ID'] = data['IMDB ID'].astype(str)\n",
      "imdbs = map(itemgetter(0), corpus)\n",
      "for i,imdb in enumerate(data['IMDB ID']):\n",
      "    data['IMDB ID'][i] = imdb.zfill(7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_missing = []\n",
      "k = len(data.columns)\n",
      "for i in xrange(len(data)):\n",
      "    num_missing.append(k - np.sum(pd.notnull(data.irow(i))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['num_missing'] = num_missing\n",
      "data = data.sort(columns='num_missing')\n",
      "data = data.drop_duplicates(cols='IMDB ID')\n",
      "imdb_ids = np.array(data['IMDB ID'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_mat = np.zeros((len(data), 50))\n",
      "script_len_ary = np.zeros(len(data))\n",
      "for i,id in enumerate(imdb_ids):\n",
      "    for f,val in topic_features[id]:\n",
      "        tf_mat[i,f] = val\n",
      "    script_len_ary[i] = script_len[id]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for j in xrange(50):\n",
      "    data[str(j)] = tf_mat[:,j]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['length'] = script_len_ary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(50):\n",
      "    fig = plt.figure()\n",
      "    plt.hist(data[str(i)], normed=True)\n",
      "    plt.title('topic %d' % i)\n",
      "    fig.savefig('topic_%d.png' % i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.to_csv('master_w_topics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('master_w_topics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['Action & Adventure', 'Animation', 'Art House & International', 'Classics',\n",
      " 'Comedy', 'Cult Movies', 'Documentary', 'Drama', 'Horror', 'Kids & Family',\n",
      " 'Musical & Performing Arts', 'Mystery & Suspense', 'Romance', 'Science Fiction & Fantasy',\n",
      " 'Special Interest', 'Television', 'Western']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '%25s | %14s | %14s' % ('Genre', 'Avg. Length', 'Avg. Runtime')\n",
      "print '-'*63\n",
      "for g in genres:\n",
      "    print '%25s |%10.1f words|%8.1f minutes' % (g, np.mean(data[data[g] == 1].length), np.mean(data[data[g]==1].runtime))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                    Genre |    Avg. Length |   Avg. Runtime\n",
        "---------------------------------------------------------------\n",
        "       Action & Adventure |    3405.7 words|   115.6 minutes\n",
        "                Animation |    2872.1 words|    77.0 minutes\n",
        "Art House & International |    2860.5 words|   108.2 minutes\n",
        "                 Classics |    3214.3 words|   114.8 minutes\n",
        "                   Comedy |    2685.0 words|   106.0 minutes\n",
        "              Cult Movies |    2681.0 words|   114.8 minutes\n",
        "              Documentary |    4182.0 words|    76.8 minutes\n",
        "                    Drama |    3108.2 words|   120.6 minutes\n",
        "                   Horror |    2771.3 words|   101.5 minutes\n",
        "            Kids & Family |    2697.0 words|    97.2 minutes\n",
        "Musical & Performing Arts |    2861.3 words|   108.6 minutes\n",
        "       Mystery & Suspense |    3183.9 words|   115.9 minutes\n",
        "                  Romance |    2880.7 words|   115.8 minutes\n",
        "Science Fiction & Fantasy |    3293.7 words|   109.3 minutes\n",
        "         Special Interest |    2911.5 words|   120.5 minutes\n",
        "               Television |    2596.6 words|   109.8 minutes\n",
        "                  Western |    3697.0 words|   128.2 minutes\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we use logistic regression with L1 regularization to predict the probability that a movie belongs to a given genre. Since movies can belong to more than one genre, we run a logistic regression model for each genre."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_logreg(genre):\n",
      "    y = np.array(data[genre])\n",
      "    X = np.zeros((len(data),50))\n",
      "    \n",
      "    for i in xrange(50):\n",
      "        X[:,i] = data[str(i)]\n",
      "    \n",
      "    mod = linear_model.LogisticRegression()\n",
      "    trnx,tstx,trny,tsty = cross_validation.train_test_split(X,y)\n",
      "    mod.fit(trnx,trny)\n",
      "    return np.sum(tsty == mod.predict(tstx)) / float(len(tsty)), mod.coef_[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pure_chance(genre):\n",
      "    '''\n",
      "    Given a genre, if we were to guess movie classification based on proportion,\n",
      "    how often would we be correct?\n",
      "    '''\n",
      "    y = np.array(data[genre])\n",
      "    prob = np.sum(y) / float(len(y))\n",
      "    return np.max([prob, 1-prob])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['Action & Adventure', 'Animation', 'Art House & International', 'Classics',\n",
      " 'Comedy', 'Cult Movies', 'Documentary', 'Drama', 'Horror', 'Kids & Family',\n",
      " 'Musical & Performing Arts', 'Mystery & Suspense', 'Romance', 'Science Fiction & Fantasy',\n",
      " 'Special Interest', 'Television', 'Western']\n",
      "\n",
      "print '%25s | %23s | %11s | %10s' % ('Genre', 'Prediction Success Rate', 'Pure Chance', 'Num. Movies')\n",
      "print '%s' % '-'*80\n",
      "for g in genres:\n",
      "    prob,_ = run_logreg(g)\n",
      "    print '%25s | %15.2f%8s | %8.2f%3s | %8d' % (g, prob, '', pure_chance(g), '', np.sum(data[g]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unsurprisingly, genres that are not well represented in our corpus cannot be predicted very easily. That is, without many training examples, it is very difficult to improve on pure guessing. Accordingly, we only look at four genres for predicting box office success."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = ['Action & Adventure', 'Comedy', 'Drama', 'Science Fiction & Fantasy']\n",
      "\n",
      "print '%25s | %23s | %11s | %10s' % ('Genre', 'Prediction Success Rate', 'Pure Chance', 'Num. Movies')\n",
      "print '%s' % '-'*80\n",
      "for g in genres:\n",
      "    prob,_ = run_logreg(g)\n",
      "    print '%25s | %15.2f%8s | %8.2f%3s | %8d' % (g, prob, '', pure_chance(g), '', np.sum(data[g]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given a new script, but no knowledge of what genre the movie belongs to, the following could be used for features in the box office success prediction model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coefs = np.zeros((50,len(genres)))\n",
      "\n",
      "for i,g in enumerate(genres):\n",
      "    _, coefs[:,i] = run_logreg(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for g in genres:\n",
      "    y = np.array(data[g])\n",
      "    X = np.zeros((len(data),50))\n",
      "    \n",
      "    for i in xrange(50):\n",
      "        X[:,i] = data[str(i)]\n",
      "    \n",
      "    mod = linear_model.LogisticRegression()\n",
      "    mod.fit(X,y)\n",
      "    data['prob_%s' % g] = map(itemgetter(1), mod.predict_proba(X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(data['prob_Action & Adventure'], normed=True)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we build a Bayesian ridge regression model of gross box office receipts. We use the topics we extracted with LDA and other variables that we pulled from movie databases. Bayesian ridge regression was chosen in order to avoid overfitting and because we wanted to test a relatively high dimensional model (because of the 50 topics)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod = linear_model.BayesianRidge()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a dummy variable for R rating."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "R = np.array(data['mpaa_rating'] == 'R', dtype=np.float64)\n",
      "data['R'] = R"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create numpy array from pandas dataframe and normalize the dependent variable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X1 = np.zeros((len(data),50))\n",
      "for i in xrange(50):\n",
      "    X1[:,i] = np.array(data[str(i)])\n",
      "\n",
      "y = np.array(data['Gross'])\n",
      "X2 = np.array(data[['Budget', 'Critics Score', 'Audience Score', \n",
      "                    'Action & Adventure', 'Comedy', 'Drama', 'length', \n",
      "                    'runtime', 'R', 'Oscar Wins']])\n",
      "\n",
      "X = np.hstack((X1,X2))\n",
      "\n",
      "indices = ~np.isnan(y)\n",
      "\n",
      "for i in xrange(X.shape[1]):\n",
      "    indices = np.logical_and(indices, ~np.isnan(X[:,i]))\n",
      "\n",
      "y = y[indices]\n",
      "X = X[indices,:]\n",
      "\n",
      "y = (y - y.mean()) / y.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split data into training and test set, fit the regression model and plot predicted observed test set gross receipts vs. predicted test set gross receipts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trnx, tstx, trny, tsty = cross_validation.train_test_split(X,y)\n",
      "mod.fit(trnx,trny)\n",
      "\n",
      "b = np.polyfit(mod.predict(tstx), tsty, 1)\n",
      "pts = np.array([mod.predict(tstx).min(), mod.predict(tstx).max()])\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.plot(mod.predict(tstx), tsty, 'o')\n",
      "plt.plot(pts, b[1] + b[0]*pts)\n",
      "remove_border()\n",
      "plt.xlabel('prediction')\n",
      "plt.ylabel('observed')\n",
      "plt.title('test set performance (normalized gross box office)')\n",
      "fig.savefig('test_set_perf.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some regression diagnostics:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod.fit(X,y)\n",
      "print 'R^2  = %.3f' % mod.score(tstx,tsty)\n",
      "print 'rmse = %.3f' % np.sqrt(mean_squared_error(tsty,mod.predict(tstx)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br></br>\n",
      "<b><font size=3> Supplementary References </font></b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>Recent attempts to classify Box Office and the \"star effect\" in movie-making:</p>\n",
      "\n",
      "<a href=\"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0071226\" target=\"_blank\"> Early Prediction of Movie Box Office Success Based on Wikipedia Activity Big Data </a>, PLoS ONE, Aug 2013.\n",
      "\n",
      "<a href=\"http://www.hollywoodreporter.com/news/google-unveils-model-predict-box-563660\" target=\"_blank\"> Google Unveils Model to Predict Box Office Success </a>, Hollywood Reporter, June 2013.\n",
      "\n",
      "<p>Papers on Box Office success which helped us pick script and movie features to use in our Box Office prediction model:</p>\n",
      "\n",
      "<a href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1689294 \" target=\"_blank\"> Impact of Star and Movie Buzz on Motion Picture Distribution and Box Office Revenue </a> -> R Rating, Star Academy Awards, Budget, Critical Reviews.\n",
      " \n",
      "<a href=\"http://catt.bus.okstate.edu/sharda/research/Forecasting%20Box-Office%20Receipts100102.pdf\" target=\"_blank\"> Forecasting Box-Office Receipts of Motion Pictures Using Neural Networks </a> -> Rating, Genre.\n",
      " \n",
      "<a href=\"http://faculty-staff.ou.edu/B/Suman.Basuroy-1/files/7.pdf\" target=\"_blank\"> How Critical Are Critical Reviews? The Box Office Effects of Film Critics, Star Power, and Budgets </a> -> Ratings, Awards.\n",
      " \n",
      "<a href=\"http://www.ser.tcu.edu/2005/SER2005%20Terry%20Butler%20DeArmond%20137-148.pdf\"> The Determinants of Domestic Box Office Performance in the Motion Picture Industry </a> -> Ratings, Awards.\n",
      " \n",
      "<a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.0022-3840.1983.1604_159.x/abstract\"> Predicting Success of Theatrical Movies: An Empirical Study </a> -> Overview of important factors to consider, to try to make into features."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}